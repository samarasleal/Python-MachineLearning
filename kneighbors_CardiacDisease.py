# -*- coding: utf-8 -*-
"""kneighbors_example.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/gist/samarasleal/8c99ee50aba03c9ef3ed5fe1e3d97f44/kneighbors_example.ipynb

1- Bibliotecas
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score

"""2- Importar os dados

Problema: Predição de morte por doenças cardíacas (y - variável dependente ou de reposta).

Classes: DEATH_EVENT = 0 (Não) e 1 (Sim)

12 variáveis independentes ou features (x) :  age, anaemia, high blood pressure, creatinine phosphokinase, diabetes, ejection fraction, platelets, sex, serum creatinine, serum sodium, smoking, time.
"""

url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00519/heart_failure_clinical_records_dataset.csv'
col_names = ['age', 'anaemia', 'creatinine_phosphokinase', 'diabetes', 'ejection_fraction', 'high_blood_pressure', 'platelets','serum_creatinine','serum_sodium', 'sex', 'smoking', 'time', 'DEATH_EVENT']
HF = pd.read_csv(url, names = col_names,  header = None)
# Tirando a primeira linha do CSV que só contém string 'nomes das colunas' - Não está configurada como header
HF = HF.iloc[1:]

"""3- Explorar os dados"""

# HF.info()
HF.head()
# HF['DEATH_EVENT'].unique()
# Pré-processamento dos dados
# print(HF['DEATH_EVENT'].value_counts())

"""4- Dividir o Dataset"""

y = HF['DEATH_EVENT']
x = HF.iloc[:,0:12]

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)
x_train.shape
x_test.shape

"""5- Algoritmo Machine Learning (Treino)


"""

knn = KNeighborsClassifier()
knn.fit(x_train,y_train)

"""5- Algoritmo Machine Learning (Predição)

"""

knn.predict(x_test)

"""7- Algoritmo Machine Learning (Acurácia)"""

print("Acurácia %.2f" %(knn.score(x_test,y_test)))

"""8- Matriz de Confusão

Na matriz de confusão abaixo pode ser observado que o modelo está pouco ajustado (até mesmo pelo percentual de acurácia encontrado 0.66%, uma indicação de underfitting, talvez a base de dados não seja suficiente ou treinamento desbalançeado). O modelo acertou 53 vezes para a Classe 0 e 6 para a classe 1. 
"""

confusion_matrix(y_test, knn.predict(x_test))